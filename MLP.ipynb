{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5329: Assignment 1 Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team member 2  Name: Dongqi Xu SID: 480529282 unikey: doxu4474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team member 1  Name: Yujun Liu   SID:480422097 unikey: yliu7078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial setup and data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py                     # To read the raw datasets\n",
    "import numpy as np              # To do linear algebra \n",
    "import matplotlib.pyplot as pl  # To plot \n",
    "from time import time           # To calculate the timing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 128)\n",
      "(50000,)\n",
      "(10000, 128)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])[0:50000]\n",
    "with h5py.File('train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])[0:50000]\n",
    "    \n",
    "with h5py.File('train_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])[50000:]\n",
    "with h5py.File('train_label.h5','r') as H:\n",
    "    test_label = np.copy(H['label'])[50000:]\n",
    "    \n",
    "    \n",
    "with h5py.File(\"test_128.h5\",'r') as H:\n",
    "    pred_data = np.copy(H['data'])[:100]\n",
    "    \n",
    "print(data.shape)\n",
    "print(label.shape)\n",
    "print(test_data.shape)\n",
    "print(test_label.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 See the training data label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl.figure(figsize=(5,5))\n",
    "sns.set(style='white')\n",
    "ax_label = sns.countplot(y = label, palette=\"RdBu\")\n",
    "ax_label.set(ylabel = 'Label', xlabel = 'Count')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We transform the data to array type. Then normalize the input data by $x_i=\\frac{x_i-\\mu}{\\delta}$. Finally transform data into one-hot label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(label[0])\n",
    "print(test_label[0])\n",
    "label = np.array(np.eye(10)[label.reshape(-1)], dtype=float)\n",
    "test_label = np.array(np.eye(10)[test_label.reshape(-1)], dtype=float)\n",
    "print(label[0])\n",
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_data):\n",
    "    \n",
    "    mu = input_data.mean()\n",
    "    sigma = input_data.std()\n",
    "    normalized_data = (input_data - mu) / sigma\n",
    "    \n",
    "    return normalized_data\n",
    "\n",
    "#print(data[0])\n",
    "data = normalize(data)\n",
    "test_data = normalize(test_data)\n",
    "pred_data = normalize(pred_data)\n",
    "#print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(data, dtype=float)\n",
    "test_data = np.array(test_data, dtype=float)\n",
    "train_label = np.array(label, dtype=float)\n",
    "test_label= np.array(test_label, dtype=float)\n",
    "pred_data = np.array(pred_data, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Activation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation:\n",
    "    \n",
    "    def __init__(self, activation='relu'):            \n",
    "        if activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "\n",
    "        if activation == 'relu':\n",
    "            self.f = self.__relu\n",
    "            self.f_deriv = self.__relu_deriv\n",
    "        if activation == 'leaky relu':\n",
    "            self.f = self.leaky_relu\n",
    "            self.f_deriv = self.leaky_relu_deriv\n",
    "    \n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def leaky_relu (self,x):\n",
    "        return np.maximum(x,0.1*x)  \n",
    "\n",
    "    def leaky_relu_deriv (self,a):\n",
    "        # a = np.maximum(x,0.1*x)\n",
    "        a[a<0] = 0.1\n",
    "        a[a>=0] = 1\n",
    "        return a\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        return 1.0 - a**2\n",
    "\n",
    "    def __relu(self, x):\n",
    "        x = x*(x>0)\n",
    "        return x\n",
    "\n",
    "    def __relu_deriv(self, a):\n",
    "        a = 1.0*(a>0)\n",
    "        return a  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Input and output layer classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to convinent for forward and backward propogation processing of input and output layer, we create a class for input and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IO_Layer:\n",
    "    def __init__(self, n_in, n_out, W=None, b=None, activation='relu'):\n",
    "        self.input = None\n",
    "        self.activation = Activation(activation).f\n",
    "        self.activation_deriv = Activation(activation).f_deriv\n",
    "\n",
    "        # Kaiming He initialization \n",
    "        self.W = np.random.randn(n_in, n_out) * np.sqrt(2.0 / n_in) # w is to N(mean = 0, std = sqrt( 2.0 / fan_in))\n",
    "        self.b = np.zeros(n_out,)\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "\n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        self.velocity_W = np.zeros(self.W.shape)\n",
    "        self.velocity_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        self.sqr_grad_W = np.zeros(self.W.shape) \n",
    "        self.sqr_grad_b = np.zeros(self.b.shape)        \n",
    "        \n",
    "        \n",
    "\n",
    "    # create initial parameters for each layer \n",
    "    def forward(self, input):\n",
    "\n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (lin_output if self.activation is None else self.activation(lin_output))\n",
    "        self.input = input\n",
    "        return self.output\n",
    "    \n",
    "    # to predict unlabele   \n",
    "    def forward_predict(self, input):\n",
    "    \n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (lin_output if self.activation is None else self.activation(lin_output))\n",
    "        self.input = input\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, delta):\n",
    "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
    "        self.grad_b = np.sum(delta)\n",
    "        delta_ = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "        # return delta_ for next layer\n",
    "        return delta_\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Hidden Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer:\n",
    "    def __init__(self, n_in, n_out, W=None, b=None, activation='relu', \n",
    "                 dropout=False, weight_decay=False):\n",
    "        \n",
    "        self.input = None\n",
    "        self.activation = Activation(activation).f\n",
    "        self.activation_deriv = Activation(activation).f_deriv\n",
    "        \n",
    "        self.W = np.random.randn(n_in, n_out) * np.sqrt(1.0 / n_in)\n",
    "        self.b = np.zeros(n_out,)\n",
    "        self.n_in = n_in\n",
    "        self.n_out = n_out\n",
    "        \n",
    "        #to set dropout P\n",
    "        self.dropout = 1-dropout\n",
    "        #whether do weight_decay\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        #parameters for GD\n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        #parameters for momentum and adam\n",
    "        self.velocity_W = np.zeros(self.W.shape)\n",
    "        self.velocity_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        self.sqr_grad_W = np.zeros(self.W.shape) \n",
    "        self.sqr_grad_b = np.zeros(self.b.shape)        \n",
    "\n",
    "        # parameters for BN\n",
    "        self.gamma_BN = np.ones((1, n_in))\n",
    "        self.beta_BN = 0 \n",
    "        self.grad_gamma_BN = np.ones(self.gamma_BN.shape)\n",
    "        self.grad_beta_BN = 0 \n",
    "        self.BN_mean_total = []\n",
    "        self.BN_var_total = []\n",
    "    \n",
    "\n",
    "    def forward(self, input,BN=False):\n",
    "        \n",
    "        # pass output to next layer\n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (lin_output if self.activation is None else self.activation(lin_output))\n",
    "        self.input = input\n",
    "        if self.dropout is True:\n",
    "            \n",
    "            prob = np.random.binomial(1,self.dropout,size=self.W)\n",
    "            self.output *= prob\n",
    "        \n",
    "        \n",
    "        if BN is True:\n",
    "            input_mean = input.mean(axis=0, keepdims=True)\n",
    "            input_var = input.var(axis=0, keepdims=True)\n",
    "            input = (input - input_mean) / np.sqrt(input_var + 1e-5)\n",
    "            input = input * self.gamma_BN + self.beta_BN\n",
    "            self.BN_mean_total.append(input_mean)\n",
    "            self.BN_var_total.append(input_var)            \n",
    "               \n",
    "        return self.output\n",
    "\n",
    "    def forward_predict(self, input,BN=False):\n",
    "        if BN is True:\n",
    "            input_mean = np.mean(self.BN_mean_total)\n",
    "            input_var = np.mean(self.BN_var_total)\n",
    "            input = (input - input_mean) / np.sqrt(input_var + 1e-5)\n",
    "            input = input * self.gamma_BN + self.beta_BN\n",
    "                    \n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (lin_output if self.activation is None else self.activation(lin_output))\n",
    "        self.input = input\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, delta,BN=False):\n",
    "\n",
    "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
    "        self.grad_b = np.sum(delta)\n",
    " \n",
    "        delta_ = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "    \n",
    "        if BN is True:\n",
    "            self.grad_gamma_BN = np.mean(delta_, axis=0, keepdims=True) * self.gamma_BN\n",
    "            self.grad_beta_BN = np.mean(delta_)\n",
    "        \n",
    "            delta_ = delta_ * self.gamma_BN    \n",
    "        return delta_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_layers, hidden_layers, output_layers, activation='leaky relu',softmax=False,\n",
    "                 dropout=False, weight_decay=False):\n",
    "        \n",
    "        # create list to store all parameters\n",
    "        self.layers = []\n",
    "        self.params = []\n",
    "\n",
    "        self.activation = activation\n",
    "        self.softmax = softmax\n",
    "        \n",
    "        # set whether implement weight decay and init\n",
    "        self.weight_decay = weight_decay\n",
    "        if weight_decay is True:\n",
    "            print(\"Using weight_decay\")\n",
    "\n",
    "\n",
    "\n",
    "        # create input layer\n",
    "        self.layers.append(IO_Layer(input_layers, hidden_layers[0], activation=activation))\n",
    "        # add hidden layers\n",
    "        for i in range(len(hidden_layers) - 1):\n",
    "            self.layers.append(HiddenLayer(hidden_layers[i], hidden_layers[i + 1], activation=activation, dropout=dropout,\n",
    "                                          weight_decay=self.weight_decay))\n",
    "        # add output layer\n",
    "        self.layers.append(IO_Layer(hidden_layers[-1], output_layers, activation=activation))\n",
    "        print(\"===============================================\")\n",
    "        print(\"Defaultly calculte cross-entropy-loss of output\")\n",
    "        print(\"===============================================\")\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(input)\n",
    "            input = output\n",
    "        return output\n",
    "\n",
    "    def forward_predict(self, input):\n",
    "        # only use it in predict\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward_predict(input)\n",
    "            input = output\n",
    "        return output\n",
    "\n",
    "    def criterion(self, y, y_hat):\n",
    "        if not self.softmax:\n",
    "            activation_deriv = Activation(self.activation).f_deriv\n",
    "            error = y - y_hat\n",
    "            loss = error**2 \n",
    "            delta = -error * activation_deriv(y_hat) / 512\n",
    "            \n",
    "            loss = np.sum(loss)\n",
    "            \n",
    "        if self.softmax:\n",
    "            y_ = np.exp(y_hat-np.max(y_hat,axis=1,keepdims=True))\n",
    "            y_hat = y_ / (np.sum(y_, axis=1, keepdims=True))\n",
    "             \n",
    "            loss = -np.sum(y*(np.log(y_hat)))\n",
    "            delta =  -(y-y_hat)/512           \n",
    "            #print(loss,delta)\n",
    "        return loss, delta\n",
    "\n",
    "    def backward(self, delta):\n",
    "        for layer in reversed(self.layers):\n",
    "            delta = layer.backward(delta)\n",
    "\n",
    "    def update(self,learning_rate=0.001,it=0,BN=False):\n",
    "        if BN is True:\n",
    "            layer.gamma_BN -= lr * layer.grad_gamma_BN\n",
    "            layer.beta_BN -= lr * layer.grad_beta_BN            \n",
    "            layer.velocity_W = gamma_MT * layer.velocity_W + lr * layer.grad_W\n",
    "            layer.W -= layer.velocity_W\n",
    "            layer.velocity_b = gamma_MT * layer.velocity_b + lr * layer.grad_b\n",
    "            layer.b -= layer.velocity_b      \n",
    "\n",
    "        for layer in self.layers:\n",
    "            if self.weight_decay:\n",
    "            #L_new_W=L_old_W+0.5*lambda||W||**2  -> W-grad_W = W - learning_rate*(delta+lambda*W) -> (1-laerning_rate*lambda)*W-delta\n",
    "            #W = W*(1-laerning_rate*lambda)  \n",
    "                layer.W *= (1-learning_rate*self.weight_decay) \n",
    "            # Momentum\n",
    "            if self.optimizer == 'momentum':\n",
    "                \n",
    "                beta=0.9\n",
    "                layer.velocity_W = beta*layer.velocity_W + (learning_rate)*layer.grad_W\n",
    "                layer.velocity_b = beta*layer.velocity_b + (learning_rate)*layer.grad_b\n",
    "                # Update \n",
    "                layer.W -= layer.velocity_W\n",
    "                layer.b -= layer.velocity_b \n",
    "            # Adam\n",
    "            elif self.optimizer == 'adam':\n",
    "                #layer.adam_update(learning_rate,it)\n",
    "                t = it\n",
    "                beta1=0.9\n",
    "                beta2=0.999\n",
    "                epsilon=1e-3\n",
    "                # Update m\n",
    "                layer.velocity_W = beta1*layer.velocity_W + (1-beta1)*layer.grad_W\n",
    "                layer.velocity_b = beta1*layer.velocity_b + (1-beta1)*layer.grad_b\n",
    "\n",
    "                # Calculate  v\n",
    "                layer.sqr_grad_W = beta2 * layer.sqr_grad_W + (1-beta2) * np.power(layer.grad_W,2)\n",
    "                layer.sqr_grad_b = beta2 * layer.sqr_grad_b + (1-beta2) * np.power(layer.grad_b,2)\n",
    "        \n",
    "                # Correct m_hat\n",
    "                velocity_corrected_W = layer.velocity_W / (1-beta1**(t+1)) \n",
    "                velocity_corrected_b = layer.velocity_b / (1-beta1**(t+1))  \n",
    "\n",
    "                # Correct v_hat\n",
    "                sqr_grad_corrected_W = layer.sqr_grad_W / (1-beta2**(t+1)) \n",
    "                sqr_grad_corrected_b = layer.sqr_grad_b / (1-beta2**(t+1))          \n",
    "        \n",
    "                # Update\n",
    "                layer.W -= learning_rate * (velocity_corrected_W/(np.sqrt(sqr_grad_corrected_W+epsilon)))# added epsilon \n",
    "                layer.b -= learning_rate * (velocity_corrected_b/(np.sqrt(sqr_grad_corrected_b+epsilon))) # added epsilon  \n",
    "            \n",
    "            else:\n",
    "                layer.W -= learning_rate * layer.grad_W\n",
    "                layer.b -= learning_rate * layer.grad_b\n",
    "            \n",
    "\n",
    "    # mini batch training\n",
    "    def mini_batches_random(self, X, y, mini_batch_size):\n",
    "        # create mini-batches for each epoch, randomly choose elements for batches\n",
    "        num_samples = X.shape[0]\n",
    "        mini_batches = []\n",
    "\n",
    "        permutation = list(np.random.permutation(num_samples))\n",
    "        rand_X = X[permutation, :]\n",
    "        rand_y = y[permutation, :]\n",
    "\n",
    "        num_complete = num_samples // mini_batch_size\n",
    "\n",
    "        for i in range(num_complete):\n",
    "            mini_batch_X = rand_X[i * mini_batch_size: (i + 1) * mini_batch_size, :]\n",
    "            mini_batch_y = rand_y[i * mini_batch_size: (i + 1) * mini_batch_size, :]\n",
    "\n",
    "            mini_batch = (mini_batch_X, mini_batch_y)\n",
    "            mini_batches.append(mini_batch)\n",
    "\n",
    "        if num_samples % mini_batch_size != 0:\n",
    "            mini_batch_X = rand_X[num_complete * mini_batch_size:, :]\n",
    "            mini_batch_y = rand_y[num_complete * mini_batch_size:, :]\n",
    "\n",
    "            mini_batch = (mini_batch_X, mini_batch_y)\n",
    "            mini_batches.append(mini_batch)\n",
    "        return mini_batches\n",
    "    \n",
    "    def fit(self, X, y, learning_rate=0.1, epochs=100, gd='mini_batch', mini_batch_size=64, optimizer=None,BN=False):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        self.optimizer = optimizer\n",
    "        self.BN=BN\n",
    "        epochs += 1 # to revise the range of epochs, plus 1 for modification\n",
    "        to_return = np.zeros(epochs)\n",
    "        \n",
    "        if gd == 'SGD':\n",
    "            for k in range(epochs):\n",
    "                loss = 0\n",
    "                i = np.random.randint(X.shape[0])\n",
    "                # forward pass\n",
    "                y_hat = self.forward(X[i])\n",
    "                # backward pass\n",
    "                loss, delta = self.criterion(y[i], y_hat)\n",
    "                self.backward(delta)\n",
    "                # update\n",
    "                self.update(learning_rate, momentum, gamma_MT)\n",
    "                to_return[k] = np.mean(loss)\n",
    "                if k%500 == 0 and k!=0:\n",
    "                    print(\"the epoch {} loss: {}\".format(str(k), to_return[k]))\n",
    "\n",
    "        # Implement Mini Batch\n",
    "        if gd == 'mini_batch':\n",
    "            for k in range(epochs):\n",
    "                loss = np.zeros(X.shape[0])\n",
    "                mini_batches = self.mini_batches_random(X, y, mini_batch_size)\n",
    "\n",
    "                for it, mini_batch in enumerate(mini_batches):\n",
    "                    loss_it = 0\n",
    "                    (mini_batch_X, mini_batch_y) = mini_batch\n",
    "                    \n",
    "                    y_hat = self.forward(mini_batch_X)\n",
    "                    \n",
    "                    loss_it, delta = self.criterion(mini_batch_y, y_hat)\n",
    "                    loss[it] = np.mean(loss_it)\n",
    "                    \n",
    "                    self.backward(delta)\n",
    "                    self.update(learning_rate,it)\n",
    "\n",
    "                    to_return[k] = np.mean(loss)\n",
    "                # print loss of epochs\n",
    "                if k%2 == 0 and k!=0:\n",
    "                    print(\"the epoch {} loss: {}\".format(str(k), to_return[k]))\n",
    "                    \n",
    "        return to_return\n",
    "\n",
    "    def predict(self, x, model):\n",
    "        x = np.array(x)\n",
    "        output = model.forward_predict(x)\n",
    "        if self.softmax is True:\n",
    "            x = np.array(x)\n",
    "            output = model.forward_predict(x)\n",
    "            exps_out = np.exp(output-np.max(x,axis=1,keepdims=True))\n",
    "            output = exps_out / (np.sum(exps_out, axis=1, keepdims=True))\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Classifier Development, Training and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Defaultly calculte cross-entropy-loss of output\n",
      "===============================================\n",
      "the epoch 2 loss: 0.6374233309804971\n",
      "the epoch 4 loss: 0.5505936166952546\n",
      "the epoch 6 loss: 0.5038026519347868\n",
      "the epoch 8 loss: 0.47233821518874547\n",
      "the epoch 10 loss: 0.45064557097634655\n",
      "the epoch 12 loss: 0.43392706213689897\n",
      "the epoch 14 loss: 0.4202742864411453\n",
      "the epoch 16 loss: 0.4090172792156234\n",
      "the epoch 18 loss: 0.4003388217637358\n",
      "the epoch 20 loss: 0.3915179671515108\n",
      "the epoch 22 loss: 0.38422388358649684\n",
      "the epoch 24 loss: 0.3790088455463915\n",
      "the epoch 26 loss: 0.37333461093400155\n",
      "the epoch 28 loss: 0.3664700480770211\n",
      "the epoch 30 loss: 0.36120395314799186\n",
      "the epoch 32 loss: 0.35683175141674484\n",
      "the epoch 34 loss: 0.35246010011700024\n",
      "the epoch 36 loss: 0.3489648770959026\n",
      "the epoch 38 loss: 0.34450362113575334\n",
      "the epoch 40 loss: 0.3404852577513173\n",
      "the epoch 42 loss: 0.33801773263714147\n",
      "the epoch 44 loss: 0.3344143228133715\n",
      "the epoch 46 loss: 0.33084854931742047\n",
      "the epoch 48 loss: 0.32766776881879317\n",
      "the epoch 50 loss: 0.325198963481388\n",
      "the epoch 52 loss: 0.322547770608325\n",
      "the epoch 54 loss: 0.3196699730772464\n",
      "the epoch 56 loss: 0.31705152085155985\n",
      "the epoch 58 loss: 0.3151096433275784\n",
      "the epoch 60 loss: 0.31239886827597496\n",
      "the epoch 62 loss: 0.30987665597528097\n",
      "the epoch 64 loss: 0.3079443943067971\n",
      "the epoch 66 loss: 0.30560243114627733\n",
      "the epoch 68 loss: 0.30349749930900743\n",
      "the epoch 70 loss: 0.30123894692516334\n",
      "the epoch 72 loss: 0.29955902448632393\n",
      "the epoch 74 loss: 0.29857136664553574\n",
      "the epoch 76 loss: 0.2954509337285527\n",
      "the epoch 78 loss: 0.2943587843068059\n",
      "the epoch 80 loss: 0.29212494097629826\n",
      "the epoch 82 loss: 0.2906205888218602\n",
      "the epoch 84 loss: 0.2889818764758982\n",
      "the epoch 86 loss: 0.287687229812888\n",
      "the epoch 88 loss: 0.28626243174478483\n",
      "the epoch 90 loss: 0.28339228478439604\n",
      "the epoch 92 loss: 0.28224035728574703\n",
      "the epoch 94 loss: 0.28030287310397195\n",
      "the epoch 96 loss: 0.27994554867130145\n",
      "the epoch 98 loss: 0.2774571320741271\n",
      "the epoch 100 loss: 0.27666037470778015\n",
      "---------------------------------\n",
      "\n",
      "last loss:0.276660\n",
      "===============================================\n",
      "Fit time: 27.359985 seconds\n",
      "===============================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time()\n",
    "\n",
    "nn = MLP(128, [100, 64, 32], 10, 'relu', dropout=False,softmax=True,weight_decay=0) \n",
    "\n",
    "CROSS_E = nn.fit(data,label, learning_rate=0.02, epochs=100, gd='mini_batch', mini_batch_size=512,optimizer= None ,BN= False)\n",
    "\n",
    "print(\"---------------------------------\\n\")\n",
    "print('last loss:%f' % CROSS_E[-1])\n",
    "\n",
    "end_time = time()\n",
    "print(\"===============================================\")\n",
    "print(\"Fit time: %2f seconds\" % (end_time - start_time))\n",
    "print(\"===============================================\")\n",
    "pl.figure()\n",
    "pl.title('loss curve') \n",
    "pl.plot(CROSS_E, color=\"navy\")\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Calculate testing accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAcc(pred_label, real_label):\n",
    "    acc_num = 0\n",
    "    for i in range(len(pred_label)):\n",
    "        if pred_label[i].tolist() == real_label[i].tolist():\n",
    "            acc_num += 1\n",
    "            #print(pred_label[i],real_label[i])\n",
    "        #if pred_label[i].tolist() != real_label[i].tolist():\n",
    "            #print(pred_label[i],real_label[i])\n",
    "    print(\"number of correct prediction : \",acc_num)\n",
    "    acc = acc_num / len(real_label)\n",
    "    print(\"the accuracy is: {:.4%}\".format(float(acc)))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(test_data, model):\n",
    "    predictLabel = model.predict(test_data, model)\n",
    "    predict_array = np.array(predictLabel)\n",
    "    #print(predict_array)\n",
    "    predictLabel = (predict_array == predict_array.max(axis=1, keepdims=1)).astype(float)\n",
    "\n",
    "    return predictLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of correct prediction :  8775\n",
      "the accuracy is: 87.7500%\n"
     ]
    }
   ],
   "source": [
    "pred_label_test = predict_data(test_data, nn)\n",
    "acc = calculateAcc(pred_label_test, test_label)\n",
    "# show the accuracy rate of sorting test data \n",
    "#pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Build confusion matrix functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "test_pred_list = []\n",
    "for one_hot_label in pred_label_test.tolist():\n",
    "    #print(one_hot_label)\n",
    "    test_label1 = one_hot_label.index(max(one_hot_label))\n",
    "    test_pred_list.append(test_label1)\n",
    "print(len(test_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 0 2 7 9 3 1 1]\n",
      "[9, 2, 1, 0, 2, 7, 9, 3, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('train_label.h5','r') as H:\n",
    "    test_label_raw = np.copy(H['label'])[50000:]\n",
    "\n",
    "print(test_label_raw[:10])\n",
    "print(test_pred_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(testLabel, realLabel):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    #only import that labrary for drawing confusion matrix\n",
    "    CM = confusion_matrix(testLabel, realLabel, labels=np.array(range(10)))\n",
    "    fig, ax = pl.subplots(figsize=(10,8))\n",
    "    fig.suptitle(\"Confusion Matrix\", fontsize=20)\n",
    "    heatmap = ax.pcolor(CM, cmap=pl.cm.Blues)\n",
    "\n",
    "    ax.set_xticks(np.arange(CM.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(CM.shape[0]) + 0.5, minor=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    fig.colorbar(heatmap)\n",
    "    ax.set_xticklabels(np.array(range(10)), minor=False)\n",
    "    ax.set_yticklabels(np.array(range(10)), minor=False)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " build_confusion_matrix(test_pred_list,test_label_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 2, 8, 0, 2, 5, 7, 5, 1, 2, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 0, 1, 6, 7, 6, 7, 2, 1, 2, 6, 4, 2, 5, 8, 2, 2, 8, 6, 8, 0, 7, 7, 8, 5, 1, 1, 3, 4, 7, 8, 7, 0, 2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2, 0, 6, 5, 3, 6, 7, 1, 8, 0, 1, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "pred_label = predict_data(pred_data, nn)\n",
    "#print(pred_label)\n",
    "final_pred_list = []\n",
    "for one_hot_label in pred_label.tolist():\n",
    "    #print(one_hot_label)\n",
    "    true_label = one_hot_label.index(max(one_hot_label))\n",
    "    final_pred_list.append(true_label)\n",
    "    \n",
    "f = h5py.File('predicted_labels.h5','w')   \n",
    "f['data'] = pred_data \n",
    "f['labels'] = final_pred_list          \n",
    "f.close() \n",
    "\n",
    "print(final_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(final_pred_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
